{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30588,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Google's mT5\n",
        "\n",
        "mT5 is pretrained on the mC4 corpus, covering 101 languages:\n",
        "\n",
        "Afrikaans, Albanian, Amharic, Arabic, Armenian, Azerbaijani, Basque, Belarusian, Bengali, Bulgarian, Burmese, Catalan, Cebuano, Chichewa, Chinese, Corsican, Czech, Danish, Dutch, English, Esperanto, Estonian, Filipino, Finnish, French, Galician, Georgian, German, Greek, Gujarati, Haitian Creole, Hausa, Hawaiian, Hebrew, Hindi, Hmong, Hungarian, Icelandic, Igbo, Indonesian, Irish, Italian, Japanese, Javanese, Kannada, Kazakh, Khmer, Korean, Kurdish, Kyrgyz, Lao, Latin, Latvian, Lithuanian, Luxembourgish, Macedonian, Malagasy, Malay, Malayalam, Maltese, Maori, Marathi, Mongolian, Nepali, Norwegian, Pashto, Persian, Polish, Portuguese, Punjabi, Romanian, Russian, Samoan, Scottish Gaelic, Serbian, Shona, Sindhi, Sinhala, Slovak, Slovenian, Somali, Sotho, Spanish, Sundanese, Swahili, Swedish, Tajik, Tamil, Telugu, Thai, Turkish, Ukrainian, Urdu, Uzbek, Vietnamese, Welsh, West Frisian, Xhosa, Yiddish, Yoruba, Zulu."
      ],
      "metadata": {
        "id": "QkhjD2ef0mv-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "!pip install sacrebleu\n",
        "!pip install evaluate"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T19:42:05.232237Z",
          "iopub.execute_input": "2023-12-01T19:42:05.232590Z",
          "iopub.status.idle": "2023-12-01T19:42:42.479255Z",
          "shell.execute_reply.started": "2023-12-01T19:42:05.232557Z",
          "shell.execute_reply": "2023-12-01T19:42:42.478052Z"
        },
        "trusted": true,
        "id": "IK6qffs8qet-"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import evaluate\n",
        "from datasets import load_dataset\n",
        "from transformers import M2M100Tokenizer, M2M100ForConditionalGeneration\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T19:44:42.457333Z",
          "iopub.execute_input": "2023-12-01T19:44:42.457687Z",
          "iopub.status.idle": "2023-12-01T19:44:55.286152Z",
          "shell.execute_reply.started": "2023-12-01T19:44:42.457658Z",
          "shell.execute_reply": "2023-12-01T19:44:55.285316Z"
        },
        "trusted": true,
        "id": "hYr10zWcqeuD",
        "outputId": "ac9f82da-581b-4e6d-c018-1da66d43a770"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer\n",
        "\n",
        "checkpoint = \"google/mt5-small\" # to train LLM choose google/mt5-large\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T19:44:59.082549Z",
          "iopub.execute_input": "2023-12-01T19:44:59.083247Z",
          "iopub.status.idle": "2023-12-01T19:45:02.014635Z",
          "shell.execute_reply.started": "2023-12-01T19:44:59.083210Z",
          "shell.execute_reply": "2023-12-01T19:45:02.013693Z"
        },
        "trusted": true,
        "id": "uwkYAObiqeuE",
        "outputId": "96510eea-221f-44a3-8740-0a8df3ef4c96"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Choose language to train translation model"
      ],
      "metadata": {
        "id": "LjMsm9L6rSAX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Availiable languages:__ (\"ar\", \"cs\"), (\"ar\", \"de\"),\n",
        "    (\"cs\", \"de\"),\n",
        "    (\"ar\", \"en\"),\n",
        "    (\"cs\", \"en\"),\n",
        "    (\"de\", \"en\"),\n",
        "    (\"ar\", \"es\"),\n",
        "    (\"cs\", \"es\"),\n",
        "    (\"de\", \"es\"),\n",
        "    (\"en\", \"es\"),\n",
        "    (\"ar\", \"fr\"),\n",
        "    (\"cs\", \"fr\"),\n",
        "    (\"de\", \"fr\"),\n",
        "    (\"en\", \"fr\"),\n",
        "    (\"es\", \"fr\"),\n",
        "    (\"ar\", \"it\"),\n",
        "    (\"cs\", \"it\"),\n",
        "    (\"de\", \"it\"),\n",
        "    (\"en\", \"it\"),\n",
        "    (\"es\", \"it\"),\n",
        "    (\"fr\", \"it\"),\n",
        "    (\"ar\", \"ja\"),\n",
        "    (\"cs\", \"ja\"),\n",
        "    (\"de\", \"ja\"),\n",
        "    (\"en\", \"ja\"),\n",
        "    (\"es\", \"ja\"),\n",
        "    (\"fr\", \"ja\"),\n",
        "    (\"ar\", \"nl\"),\n",
        "    (\"cs\", \"nl\"),\n",
        "    (\"de\", \"nl\"),\n",
        "    (\"en\", \"nl\"),\n",
        "    (\"es\", \"nl\"),\n",
        "    (\"fr\", \"nl\"),\n",
        "    (\"it\", \"nl\"),\n",
        "    (\"ar\", \"pt\"),\n",
        "    (\"cs\", \"pt\"),\n",
        "    (\"de\", \"pt\"),\n",
        "    (\"en\", \"pt\"),\n",
        "    (\"es\", \"pt\"),\n",
        "    (\"fr\", \"pt\"),\n",
        "    (\"it\", \"pt\"),\n",
        "    (\"nl\", \"pt\"),\n",
        "    (\"ar\", \"ru\"),\n",
        "    (\"cs\", \"ru\"),\n",
        "    (\"de\", \"ru\"),\n",
        "    (\"en\", \"ru\"),\n",
        "    (\"es\", \"ru\"),\n",
        "    (\"fr\", \"ru\"),\n",
        "    (\"it\", \"ru\"),\n",
        "    (\"ja\", \"ru\"),\n",
        "    (\"nl\", \"ru\"),\n",
        "    (\"pt\", \"ru\"),\n",
        "    (\"ar\", \"zh\"),\n",
        "    (\"cs\", \"zh\"),\n",
        "    (\"de\", \"zh\"),\n",
        "    (\"en\", \"zh\"),\n",
        "    (\"es\", \"zh\"),\n",
        "    (\"fr\", \"zh\"),\n",
        "    (\"it\", \"zh\"),\n",
        "    (\"ja\", \"zh\"),\n",
        "    (\"nl\", \"zh\"),\n",
        "    (\"pt\", \"zh\"),\n",
        "    (\"ru\", \"zh\"),"
      ],
      "metadata": {
        "id": "4ioc5DdAuzDU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lang = \"en-ru\"\n",
        "news_en = load_dataset(\"news_commentary\", lang)\n",
        "news_en = news_en[\"train\"].train_test_split(test_size=0.2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T19:45:06.098013Z",
          "iopub.execute_input": "2023-12-01T19:45:06.098407Z",
          "iopub.status.idle": "2023-12-01T19:45:50.589977Z",
          "shell.execute_reply.started": "2023-12-01T19:45:06.098375Z",
          "shell.execute_reply": "2023-12-01T19:45:50.589228Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "60e17248e9c449758e1006cbbd5d0f2d",
            "415787636d344536831c5d20130c9ee8",
            "b8eb839bddd44c4eb2e93b0d3f447ab1",
            "",
            "aa3c55e31fe74cddb7fcd40331881743",
            "1858ba3d4b4b44bd9c1e8b988c905489",
            "3243254bd4e24e57a5946c64f608d1af",
            "6e91ab39f8a34888bdb5caaf52f1e5d5",
            "c5e10fa2bd784c3fa6b854834391c12d"
          ]
        },
        "id": "Uf7YD2ooqeuH",
        "outputId": "8fc1e885-6f45-43b5-fd96-c8c572bff236"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading builder script:   0%|          | 0.00/2.08k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "60e17248e9c449758e1006cbbd5d0f2d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading metadata:   0%|          | 0.00/7.41k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "415787636d344536831c5d20130c9ee8"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Downloading and preparing dataset news_commentary/en-ru (download: 23.70 MiB, generated: 79.42 MiB, post-processed: Unknown size, total: 103.12 MiB) to /root/.cache/huggingface/datasets/news_commentary/en-ru/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/24.8M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8eb839bddd44c4eb2e93b0d3f447ab1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split:   0%|          | 0/190104 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Dataset news_commentary downloaded and prepared to /root/.cache/huggingface/datasets/news_commentary/en-ru/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4. Subsequent calls will reuse this data.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "aa3c55e31fe74cddb7fcd40331881743"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Downloading and preparing dataset news_commentary/fr-ru (download: 21.35 MiB, generated: 72.45 MiB, post-processed: Unknown size, total: 93.80 MiB) to /root/.cache/huggingface/datasets/news_commentary/fr-ru/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/22.4M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1858ba3d4b4b44bd9c1e8b988c905489"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split:   0%|          | 0/160740 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Dataset news_commentary downloaded and prepared to /root/.cache/huggingface/datasets/news_commentary/fr-ru/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4. Subsequent calls will reuse this data.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3243254bd4e24e57a5946c64f608d1af"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Downloading and preparing dataset news_commentary/ar-ru (download: 27.32 MiB, generated: 100.90 MiB, post-processed: Unknown size, total: 128.22 MiB) to /root/.cache/huggingface/datasets/news_commentary/ar-ru/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/28.6M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e91ab39f8a34888bdb5caaf52f1e5d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split:   0%|          | 0/84455 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Dataset news_commentary downloaded and prepared to /root/.cache/huggingface/datasets/news_commentary/ar-ru/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4. Subsequent calls will reuse this data.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5e10fa2bd784c3fa6b854834391c12d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Data preprocessing and tokenization"
      ],
      "metadata": {
        "id": "qwzqzenSv51Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    target_lang=\"ru\"\n",
        "    source_lang=\"en\"\n",
        "    prefix = \"translate English to Russian: \"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(checkpoint,\n",
        "                                            src_lang=\"en\",\n",
        "                                            tgt_lang=\"ru\")\n",
        "\n",
        "    inputs = [prefix + example[source_lang] for example in examples[\"translation\"]]\n",
        "    targets = [example[target_lang] for example in examples[\"translation\"]]\n",
        "    model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True)\n",
        "    return model_inputs"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T19:48:45.406664Z",
          "iopub.execute_input": "2023-12-01T19:48:45.407052Z",
          "iopub.status.idle": "2023-12-01T19:48:45.417508Z",
          "shell.execute_reply.started": "2023-12-01T19:48:45.407022Z",
          "shell.execute_reply": "2023-12-01T19:48:45.416454Z"
        },
        "trusted": true,
        "id": "Wb-qkaelqeuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_news_en = news_en.map(preprocess_function, batched=True)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T19:48:49.163608Z",
          "iopub.execute_input": "2023-12-01T19:48:49.163993Z",
          "iopub.status.idle": "2023-12-01T20:10:03.849544Z",
          "shell.execute_reply.started": "2023-12-01T19:48:49.163962Z",
          "shell.execute_reply": "2023-12-01T20:10:03.848643Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "b12a084998754472aa8050da1de5fbce",
            "2e66cab7b0f749fa8406da04612485d1",
            "5fc642a04e2546898c8b0e60b4d4aada",
            "0440553b7e3a4417b74606d4a460e7d1",
            "97f86ad66b5642a8a3ce64b95a1395bd",
            "b47780a31ed5455abff9f0d8bc070fc0"
          ]
        },
        "id": "6MX__iU_qeuJ",
        "outputId": "16aa2481-2af0-4bf7-ec9f-899651ceed7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/153 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b12a084998754472aa8050da1de5fbce"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:473: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/39 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e66cab7b0f749fa8406da04612485d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/129 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5fc642a04e2546898c8b0e60b4d4aada"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/33 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0440553b7e3a4417b74606d4a460e7d1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/68 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "97f86ad66b5642a8a3ce64b95a1395bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/17 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b47780a31ed5455abff9f0d8bc070fc0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "\n",
        "    return preds, labels\n",
        "\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    result = {\"bleu\": result[\"score\"]}\n",
        "\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "    return result\n",
        "\n",
        "metric = evaluate.load(\"sacrebleu\") # choose metric"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T20:10:20.824991Z",
          "iopub.execute_input": "2023-12-01T20:10:20.825900Z",
          "iopub.status.idle": "2023-12-01T20:10:21.711714Z",
          "shell.execute_reply.started": "2023-12-01T20:10:20.825865Z",
          "shell.execute_reply": "2023-12-01T20:10:21.710599Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "ac2636513d0249b48435e097574779ac"
          ]
        },
        "id": "ZC5TMAehqeuJ",
        "outputId": "9e388093-0c6b-4823-d45c-33bd0e00c019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac2636513d0249b48435e097574779ac"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Model building"
      ],
      "metadata": {
        "id": "Xd0NoNmAwWv2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
        "tokenizer =  AutoTokenizer.from_pretrained(checkpoint)\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T20:11:17.511049Z",
          "iopub.execute_input": "2023-12-01T20:11:17.511926Z",
          "iopub.status.idle": "2023-12-01T20:11:29.968597Z",
          "shell.execute_reply.started": "2023-12-01T20:11:17.511887Z",
          "shell.execute_reply": "2023-12-01T20:11:29.967800Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "7a7e8a38933c4e66bb773c20611c9721",
            "0d34aee53545433ab835cb4d6b8f3ec9"
          ]
        },
        "id": "PxhlRktyqeuK",
        "outputId": "5838df75-4623-41af-f128-667228d89b7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading pytorch_model.bin:   0%|          | 0.00/1.20G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a7e8a38933c4e66bb773c20611c9721"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d34aee53545433ab835cb4d6b8f3ec9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"my_awesome_opus_books_model\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=2,\n",
        "    predict_with_generate=True,\n",
        ")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T20:12:04.181314Z",
          "iopub.execute_input": "2023-12-01T20:12:04.181700Z",
          "iopub.status.idle": "2023-12-01T20:12:04.218831Z",
          "shell.execute_reply.started": "2023-12-01T20:12:04.181672Z",
          "shell.execute_reply": "2023-12-01T20:12:04.217916Z"
        },
        "trusted": true,
        "id": "mYd0K9sXqeuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Model training"
      ],
      "metadata": {
        "id": "BUnlykxIw14b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_news_en[\"train\"].select(range(10000)),\n",
        "    eval_dataset=tokenized_news_en[\"test\"].select(range(1000)),\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T20:12:08.019527Z",
          "iopub.execute_input": "2023-12-01T20:12:08.020282Z",
          "iopub.status.idle": "2023-12-01T20:21:35.028068Z",
          "shell.execute_reply.started": "2023-12-01T20:12:08.020250Z",
          "shell.execute_reply": "2023-12-01T20:21:35.027079Z"
        },
        "trusted": true,
        "id": "7LWp0xrgqeuL",
        "outputId": "fdae54ef-236b-4efc-9534-c8c78788eec2"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:",
          "output_type": "stream"
        },
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "  ········································\n"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.16.0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20231201_201248-wqknxhhc</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/yufr/huggingface/runs/wqknxhhc' target=\"_blank\">fallen-eon-32</a></strong> to <a href='https://wandb.ai/yufr/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/yufr/huggingface' target=\"_blank\">https://wandb.ai/yufr/huggingface</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/yufr/huggingface/runs/wqknxhhc' target=\"_blank\">https://wandb.ai/yufr/huggingface/runs/wqknxhhc</a>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1250/1250 08:13, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Bleu</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>12.235700</td>\n      <td>3.617585</td>\n      <td>0.128100</td>\n      <td>10.429000</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>5.490700</td>\n      <td>3.197928</td>\n      <td>0.339300</td>\n      <td>14.476000</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1273: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n",
          "output_type": "stream"
        },
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "TrainOutput(global_step=1250, training_loss=8.1036857421875, metrics={'train_runtime': 560.7619, 'train_samples_per_second': 35.666, 'train_steps_per_second': 2.229, 'total_flos': 1655911844413440.0, 'train_loss': 8.1036857421875, 'epoch': 2.0})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model('/kaggle/working/my/')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T20:53:07.169735Z",
          "iopub.execute_input": "2023-12-01T20:53:07.170187Z",
          "iopub.status.idle": "2023-12-01T20:53:10.200884Z",
          "shell.execute_reply.started": "2023-12-01T20:53:07.170154Z",
          "shell.execute_reply": "2023-12-01T20:53:10.199870Z"
        },
        "trusted": true,
        "id": "0u1RQkzCqeuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Test the model"
      ],
      "metadata": {
        "id": "tvioLzNFw7ag"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "translator = pipeline(\"translation\", model='/working/my/')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T20:53:15.252084Z",
          "iopub.execute_input": "2023-12-01T20:53:15.252403Z",
          "iopub.status.idle": "2023-12-01T20:53:20.778746Z",
          "shell.execute_reply.started": "2023-12-01T20:53:15.252375Z",
          "shell.execute_reply": "2023-12-01T20:53:20.777616Z"
        },
        "trusted": true,
        "id": "lMS6J4-1qeuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_en = \"Hello my friend\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-12-01T20:53:37.961153Z",
          "iopub.execute_input": "2023-12-01T20:53:37.961504Z",
          "iopub.status.idle": "2023-12-01T20:53:37.967738Z",
          "shell.execute_reply.started": "2023-12-01T20:53:37.961478Z",
          "shell.execute_reply": "2023-12-01T20:53:37.966611Z"
        },
        "trusted": true,
        "id": "xLte6nonqeuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator(text_en, src_lang='en', tgt_lang='ru')"
      ],
      "metadata": {
        "id": "vobPz4AJxNg0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}