{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30588,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## LLM M2M100\n",
        "M2M100  is a multilingual encoder-decoder (seq-to-seq) model trained for Many-to-Many multilingual translation.\n",
        "\n",
        "The model that can directly translate between the 9,900 directions of 100 languages. To translate into a target language, the target language id is forced as the first generated token. To force the target language id as the first generated token, pass the forced_bos_token_id parameter to the generate method."
      ],
      "metadata": {
        "id": "u__iJI21zqwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "!pip install sacrebleu\n",
        "!pip install evaluate"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T12:17:53.837481Z",
          "iopub.execute_input": "2023-11-30T12:17:53.837849Z",
          "iopub.status.idle": "2023-11-30T12:18:31.823779Z",
          "shell.execute_reply.started": "2023-11-30T12:17:53.837809Z",
          "shell.execute_reply": "2023-11-30T12:18:31.822753Z"
        },
        "trusted": true,
        "id": "At0wCcYex4BR"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import evaluate\n",
        "from datasets import load_dataset\n",
        "from transformers import M2M100Tokenizer, M2M100ForConditionalGeneration\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T12:18:31.826369Z",
          "iopub.execute_input": "2023-11-30T12:18:31.826751Z",
          "iopub.status.idle": "2023-11-30T12:18:48.617087Z",
          "shell.execute_reply.started": "2023-11-30T12:18:31.826713Z",
          "shell.execute_reply": "2023-11-30T12:18:48.616090Z"
        },
        "trusted": true,
        "id": "cmiwElI5x4BU",
        "outputId": "3a72f51e-626e-4189-e684-76c0a16c9e1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Choose language to train translation model"
      ],
      "metadata": {
        "id": "LEHWIweCySzo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Availiable languages:__ (\"ar\", \"cs\"), (\"ar\", \"de\"),\n",
        "    (\"cs\", \"de\"),\n",
        "    (\"ar\", \"en\"),\n",
        "    (\"cs\", \"en\"),\n",
        "    (\"de\", \"en\"),\n",
        "    (\"ar\", \"es\"),\n",
        "    (\"cs\", \"es\"),\n",
        "    (\"de\", \"es\"),\n",
        "    (\"en\", \"es\"),\n",
        "    (\"ar\", \"fr\"),\n",
        "    (\"cs\", \"fr\"),\n",
        "    (\"de\", \"fr\"),\n",
        "    (\"en\", \"fr\"),\n",
        "    (\"es\", \"fr\"),\n",
        "    (\"ar\", \"it\"),\n",
        "    (\"cs\", \"it\"),\n",
        "    (\"de\", \"it\"),\n",
        "    (\"en\", \"it\"),\n",
        "    (\"es\", \"it\"),\n",
        "    (\"fr\", \"it\"),\n",
        "    (\"ar\", \"ja\"),\n",
        "    (\"cs\", \"ja\"),\n",
        "    (\"de\", \"ja\"),\n",
        "    (\"en\", \"ja\"),\n",
        "    (\"es\", \"ja\"),\n",
        "    (\"fr\", \"ja\"),\n",
        "    (\"ar\", \"nl\"),\n",
        "    (\"cs\", \"nl\"),\n",
        "    (\"de\", \"nl\"),\n",
        "    (\"en\", \"nl\"),\n",
        "    (\"es\", \"nl\"),\n",
        "    (\"fr\", \"nl\"),\n",
        "    (\"it\", \"nl\"),\n",
        "    (\"ar\", \"pt\"),\n",
        "    (\"cs\", \"pt\"),\n",
        "    (\"de\", \"pt\"),\n",
        "    (\"en\", \"pt\"),\n",
        "    (\"es\", \"pt\"),\n",
        "    (\"fr\", \"pt\"),\n",
        "    (\"it\", \"pt\"),\n",
        "    (\"nl\", \"pt\"),\n",
        "    (\"ar\", \"ru\"),\n",
        "    (\"cs\", \"ru\"),\n",
        "    (\"de\", \"ru\"),\n",
        "    (\"en\", \"ru\"),\n",
        "    (\"es\", \"ru\"),\n",
        "    (\"fr\", \"ru\"),\n",
        "    (\"it\", \"ru\"),\n",
        "    (\"ja\", \"ru\"),\n",
        "    (\"nl\", \"ru\"),\n",
        "    (\"pt\", \"ru\"),\n",
        "    (\"ar\", \"zh\"),\n",
        "    (\"cs\", \"zh\"),\n",
        "    (\"de\", \"zh\"),\n",
        "    (\"en\", \"zh\"),\n",
        "    (\"es\", \"zh\"),\n",
        "    (\"fr\", \"zh\"),\n",
        "    (\"it\", \"zh\"),\n",
        "    (\"ja\", \"zh\"),\n",
        "    (\"nl\", \"zh\"),\n",
        "    (\"pt\", \"zh\"),\n",
        "    (\"ru\", \"zh\"),"
      ],
      "metadata": {
        "id": "EcdlV2AuyhE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "news_en = load_dataset(\"news_commentary\", \"en-ru\")\n",
        "news_en = news_en[\"train\"].train_test_split(test_size=0.2)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T12:18:48.618476Z",
          "iopub.execute_input": "2023-11-30T12:18:48.619546Z",
          "iopub.status.idle": "2023-11-30T12:19:49.022643Z",
          "shell.execute_reply.started": "2023-11-30T12:18:48.619503Z",
          "shell.execute_reply": "2023-11-30T12:19:49.021631Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "88c4b46669dd431c97bd324069b38d2f",
            "b7b4067efe5648539f8c409d0b6615b3",
            "0bec0c3a615a4b2fae981749490de850",
            "",
            "a5c7581e721e4fd8b799f3ffd6a55763",
            "46266acca7d84d6d8cb6ca771d2f216e",
            "dacb5c45a4b44308a3aa96de551dbc99",
            "61cbd7660cdf4eb0abb4fb77690dd55e",
            "4978b302079841a19b96b91f5c7c4dea"
          ]
        },
        "id": "YDxfTL-dx4BZ",
        "outputId": "8d8b57e9-50d5-4402-9c65-73c5d6564a90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading builder script:   0%|          | 0.00/2.08k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88c4b46669dd431c97bd324069b38d2f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading metadata:   0%|          | 0.00/7.41k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b7b4067efe5648539f8c409d0b6615b3"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Downloading and preparing dataset news_commentary/en-ru (download: 23.70 MiB, generated: 79.42 MiB, post-processed: Unknown size, total: 103.12 MiB) to /root/.cache/huggingface/datasets/news_commentary/en-ru/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/24.8M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0bec0c3a615a4b2fae981749490de850"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split:   0%|          | 0/190104 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Dataset news_commentary downloaded and prepared to /root/.cache/huggingface/datasets/news_commentary/en-ru/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4. Subsequent calls will reuse this data.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5c7581e721e4fd8b799f3ffd6a55763"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Downloading and preparing dataset news_commentary/fr-ru (download: 21.35 MiB, generated: 72.45 MiB, post-processed: Unknown size, total: 93.80 MiB) to /root/.cache/huggingface/datasets/news_commentary/fr-ru/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/22.4M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46266acca7d84d6d8cb6ca771d2f216e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split:   0%|          | 0/160740 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Dataset news_commentary downloaded and prepared to /root/.cache/huggingface/datasets/news_commentary/fr-ru/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4. Subsequent calls will reuse this data.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dacb5c45a4b44308a3aa96de551dbc99"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Downloading and preparing dataset news_commentary/ar-ru (download: 27.32 MiB, generated: 100.90 MiB, post-processed: Unknown size, total: 128.22 MiB) to /root/.cache/huggingface/datasets/news_commentary/ar-ru/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4...\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading data:   0%|          | 0.00/28.6M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61cbd7660cdf4eb0abb4fb77690dd55e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Generating train split:   0%|          | 0/84455 [00:00<?, ? examples/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": ""
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "Dataset news_commentary downloaded and prepared to /root/.cache/huggingface/datasets/news_commentary/ar-ru/11.0.0/cfab724ce975dc2da51cdae45302389860badc88b74db8570d561ced6004f8b4. Subsequent calls will reuse this data.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/1 [00:00<?, ?it/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4978b302079841a19b96b91f5c7c4dea"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 2. Data preprocessing and tokenization"
      ],
      "metadata": {
        "id": "70nmtQPEynV7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    target_lang=\"ru\"\n",
        "    source_lang=\"en\"\n",
        "    prefix = \"translate English to Russian: \"\n",
        "    tokenizer = M2M100Tokenizer.from_pretrained(\n",
        "                                            \"facebook/m2m100_418M\", # to use LLM you may choose m2m100_1.2B\n",
        "                                            src_lang=\"en\",\n",
        "                                            tgt_lang=\"ru\")\n",
        "\n",
        "    inputs = [prefix + example[source_lang] for example in examples[\"translation\"]]\n",
        "    targets = [example[target_lang] for example in examples[\"translation\"]]\n",
        "    model_inputs = tokenizer(inputs, text_target=targets, max_length=128, truncation=True)\n",
        "    return model_inputs"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T12:19:49.024717Z",
          "iopub.execute_input": "2023-11-30T12:19:49.025026Z",
          "iopub.status.idle": "2023-11-30T12:19:49.035570Z",
          "shell.execute_reply.started": "2023-11-30T12:19:49.024982Z",
          "shell.execute_reply": "2023-11-30T12:19:49.034647Z"
        },
        "trusted": true,
        "id": "JiIgt8wsx4Ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_news_en = news_en.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T12:19:49.036787Z",
          "iopub.execute_input": "2023-11-30T12:19:49.037093Z",
          "iopub.status.idle": "2023-11-30T12:30:27.022468Z",
          "shell.execute_reply.started": "2023-11-30T12:19:49.037065Z",
          "shell.execute_reply": "2023-11-30T12:30:27.021230Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "eeb03eb2aef04ecfa770e6e26d8a6dda",
            "c6f4be168c2945f0acd29214aa48d568",
            "008c07fe605e4d87821e075f9a4937bd",
            "82824f14db4a4b8b8235a6ddd51578a6",
            "0f662563d404479dba92739b6df1452a",
            "2944dca407814973a3888fb7f1648cb1",
            "e687de1b14a64b50ad970882822b806a",
            "086871bcd5d543628fa26488c7646cdc",
            "52f809f168524350a7bee80c67a89479",
            "5362eeaa76c24cb6912dfd90e5c9f169",
            "64592d2a7aba4de587179652ab725358"
          ]
        },
        "id": "nktfs9jJx4Bb",
        "outputId": "82977751-c276-4415-a9eb-89ec49cf4e22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/153 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eeb03eb2aef04ecfa770e6e26d8a6dda"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading tokenizer_config.json:   0%|          | 0.00/272 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c6f4be168c2945f0acd29214aa48d568"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading vocab.json:   0%|          | 0.00/3.71M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "008c07fe605e4d87821e075f9a4937bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)tencepiece.bpe.model:   0%|          | 0.00/2.42M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82824f14db4a4b8b8235a6ddd51578a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/1.14k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f662563d404479dba92739b6df1452a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading config.json:   0%|          | 0.00/908 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2944dca407814973a3888fb7f1648cb1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/39 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e687de1b14a64b50ad970882822b806a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/129 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "086871bcd5d543628fa26488c7646cdc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/33 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "52f809f168524350a7bee80c67a89479"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/68 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5362eeaa76c24cb6912dfd90e5c9f169"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "  0%|          | 0/17 [00:00<?, ?ba/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "64592d2a7aba4de587179652ab725358"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "\n",
        "    return preds, labels\n",
        "\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    result = {\"bleu\": result[\"score\"]}\n",
        "\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    result = {k: round(v, 4) for k, v in result.items()}\n",
        "    return result\n",
        "\n",
        "metric = evaluate.load(\"sacrebleu\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T12:30:27.023820Z",
          "iopub.execute_input": "2023-11-30T12:30:27.024259Z",
          "iopub.status.idle": "2023-11-30T12:30:28.817080Z",
          "shell.execute_reply.started": "2023-11-30T12:30:27.024177Z",
          "shell.execute_reply": "2023-11-30T12:30:28.815092Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "25222238418e46299faa8f12d00ba9e0"
          ]
        },
        "id": "aopeMi3Mx4Bc",
        "outputId": "f86214a1-293e-4249-f623-ad3053f0ee59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading builder script:   0%|          | 0.00/8.15k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25222238418e46299faa8f12d00ba9e0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 3. Model initialization"
      ],
      "metadata": {
        "id": "2i7i_ReTyxi4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = M2M100ForConditionalGeneration.from_pretrained('facebook/m2m100_418M')\n",
        "tokenizer = M2M100Tokenizer.from_pretrained('facebook/m2m100_418M')\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T12:30:28.818543Z",
          "iopub.execute_input": "2023-11-30T12:30:28.819419Z",
          "iopub.status.idle": "2023-11-30T12:31:30.017596Z",
          "shell.execute_reply.started": "2023-11-30T12:30:28.819366Z",
          "shell.execute_reply": "2023-11-30T12:31:30.016686Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "0f2b9b981671430a9fc5c54f07b9adb9",
            "c212b0cce4e14301997c9f16102e473e"
          ]
        },
        "id": "BcVF-UEcx4Be",
        "outputId": "6dce54d0-b988-473c-d6dc-cdbf8852c894"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading pytorch_model.bin:   0%|          | 0.00/1.94G [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f2b9b981671430a9fc5c54f07b9adb9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading generation_config.json:   0%|          | 0.00/233 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c212b0cce4e14301997c9f16102e473e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"my_awesome_opus_books_model\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=2,\n",
        "    predict_with_generate=True,\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T12:31:30.018977Z",
          "iopub.execute_input": "2023-11-30T12:31:30.019367Z",
          "iopub.status.idle": "2023-11-30T12:31:30.055578Z",
          "shell.execute_reply.started": "2023-11-30T12:31:30.019330Z",
          "shell.execute_reply": "2023-11-30T12:31:30.054564Z"
        },
        "trusted": true,
        "id": "P_9Acbdvx4Bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Model training"
      ],
      "metadata": {
        "id": "OPWhVLuFzJrO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_news_en[\"train\"].select(range(10000)),\n",
        "    eval_dataset=tokenized_news_en[\"test\"].select(range(1000)),\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-11-30T12:31:30.057088Z",
          "iopub.execute_input": "2023-11-30T12:31:30.057387Z"
        },
        "trusted": true,
        "id": "OynnhGEfx4Bg",
        "outputId": "e74e807f-266f-4d63-b7b5-9c5826858557"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:",
          "output_type": "stream"
        },
        {
          "output_type": "stream",
          "name": "stdin",
          "text": "  ········································\n"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.16.0"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20231130_123326-ido2ovia</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/genius-/huggingface/runs/ido2ovia' target=\"_blank\">icy-morning-17</a></strong> to <a href='https://wandb.ai/genius-/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/genius-/huggingface' target=\"_blank\">https://wandb.ai/genius-/huggingface</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/genius-/huggingface/runs/ido2ovia' target=\"_blank\">https://wandb.ai/genius-/huggingface/runs/ido2ovia</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "\n    <div>\n      \n      <progress value='1231' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1231/1250 18:58 < 00:17, 1.08 it/s, Epoch 1.97/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Bleu</th>\n      <th>Gen Len</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.421400</td>\n      <td>1.234021</td>\n      <td>26.480300</td>\n      <td>41.297000</td>\n    </tr>\n  </tbody>\n</table><p>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model('/kaggle/working/my/')"
      ],
      "metadata": {
        "trusted": true,
        "id": "-PbY52uFx4Bh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Test the model"
      ],
      "metadata": {
        "id": "8NrPZ04BzUrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "translator = pipeline(\"translation\", model='/kaggle/working/my/')"
      ],
      "metadata": {
        "trusted": true,
        "id": "AwY6kBX7x4Bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_en = \"Hello my friend\"\n",
        "translator(text_en, src_lang='en', tgt_lang='ru')"
      ],
      "metadata": {
        "trusted": true,
        "id": "H_m_WiSnx4Bl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}